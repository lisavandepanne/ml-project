{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is a powerful method if we want to perform a classification task. Given that we have many datapoints compared to the number of features, solving the primal problem is more appropriate.\n",
    "\n",
    "In addition, we added some modification to the usual SVM method: during the training, we penalize more strongly errors regarding the label \"+1\" as it appears way less frequently than the \"-1\". This is done to push our model to have better F1-score (a metric that takes into account the unequal distribution of \"+1\" and \"-1\" labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities.helpers import *\n",
    "from utilities.Data_preprocessing_global import *\n",
    "from utilities.Hyperparameters_SVM import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to change the path for it to work\n",
    "data_path = r'C:\\Users\\natha\\Documents\\EPFL\\Cours_MA1\\ML\\ML_course\\projects\\project1 - withGit\\data\\dataset'\n",
    "#data_path = \"D:\\\\EPFL\\\\MA1\\\\Machine Learning\\\\Projet 1\\\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids, headers_train = load_csv_data(data_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See the different shapes : x_train (328135, 321), x_test (109379, 321), y_train (328135,), headers_train: 321\n",
      "After preprocessing (train) : column with missing values {}, are there NaN ? False\n",
      "After preprocessing (test) : column with missing values {}, are there NaN ? False\n",
      "See the different shapes : x_tr (328135, 169), x_val (0, 169), y_tr (328135,), y_te(0,), x_test_formatted(109379, 169)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_val, y_tr, y_val, x_train_full, x_test_formatted, remaining_headers = data_preprocess(x_train, y_train, x_test, headers_train, model_labels = {-1, 1}, ratio_miss = 0.1, ratio_train = 1, standardization = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intentionally select a split training vs validation of 100% vs 0% because this split will be done inside the K-Fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increase the iteration with gamma, because we observed in our testing that as the gamma decreased the iteration to converge were higher. And as we did not want to iterate for no significant improvement for the higher step size, we add that the maximum number of iteration is dependant on the gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def Hyperparameter2(x_tr, y_tr, penalty_factor_list, gamma_list, lambda_list, a_list, k_fold):\n",
    "    results = []\n",
    "    for penalty_factor in penalty_factor_list : \n",
    "        print(penalty_factor)\n",
    "        for gamma in gamma_list : \n",
    "            print(gamma)\n",
    "            max_iters = int(10/gamma)\n",
    "            for lambda_ in lambda_list :\n",
    "                print(lambda_) \n",
    "                for a in a_list : \n",
    "                    print(a)\n",
    "                    av_f1_score, av_loss_tr, av_loss_te = cross_validation_demo(x = x_tr, y = y_tr, k_fold=k_fold, lambda_=lambda_, a=a, penalty_factor=penalty_factor, max_iters=max_iters, gamma=gamma)\n",
    "                    # Store results in dictionary\n",
    "                    result = {\n",
    "                        \"penalty_factor\": penalty_factor,\n",
    "                        \"gamma\": gamma,\n",
    "                        \"lambda\": lambda_,\n",
    "                        \"a\": a,\n",
    "                        \"f1-score\": av_f1_score\n",
    "                    }\n",
    "                    results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters we choose to test\n",
    "k_fold = 3\n",
    "penalty_factor_list = [8] #np.linspace(8,9,2)\n",
    "max_iter = 1000\n",
    "gamma_list = [0.1, 0.01]\n",
    "lambda_list = [0.001]\n",
    "a_list = [0.1] # Power of the denominator in the decreasing step size\n",
    "\n",
    "results = Hyperparameter(x_tr, y_tr, penalty_factor_list, gamma_list, lambda_list, a_list, k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-Score: 0.32502519611641456\n",
      "Best Parameters and Metrics: {'penalty_factor': 8, 'gamma': 0.01, 'lambda': 0.001, 'a': 0.1}\n"
     ]
    }
   ],
   "source": [
    "best_f1_score, best_params = Get_best_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the best hyperparameters, we can use them to train our model one last time, on the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.01\n",
    "max_iter = int(10 / gamma)\n",
    "lambda_ = 0.001\n",
    "a = 0.1\n",
    "penalty_factor = 8\n",
    "\n",
    "w_opt, loss_tr = sgd_for_svm(y_tr, x_tr, max_iter, gamma, lambda_, a, penalty_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_limit = 0.5 #It doesn't matter here, if we say that the model_labels are {-1, 1}\n",
    "best_w = w_opt\n",
    "name = 'SVM_submission_file.csv'\n",
    "model_labels = {-1, 1}\n",
    "\n",
    "y_pred_test = submission(x_test_formatted, test_ids, best_limit, best_w, name, model_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
