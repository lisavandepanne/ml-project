{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have to change the path for it to work\n",
    "data_path = 'D:\\\\EPFL\\\\MA1\\\\Machine Learning\\\\Projet 1\\\\dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids, headers_train = load_csv_data(data_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 321)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 321)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Stadartize the input data x\n",
    "\n",
    "    Args:\n",
    "        x: numpy array of shape=(num_samples, num_features)\n",
    "\n",
    "    Returns:\n",
    "        standartized data, shape=(num_samples, num_features)\n",
    "\n",
    "    >>> standardize(np.array([[1, 2], [3, 4], [5, 6]]))\n",
    "    array([[-1.22474487, -1.22474487],\n",
    "           [ 0.        ,  0.        ],\n",
    "           [ 1.22474487,  1.22474487]])\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    mean = np.mean(x, 0)\n",
    "    std = np.std(x, 0)\n",
    "    std_data = np.zeros(x.shape)\n",
    "    for i in range(x.shape[0]):\n",
    "        std_data[i,:] = (x[i,:]-mean)/std\n",
    "    #centered_data = x - np.mean(x, axis=0)\n",
    "    #std_data = centered_data / np.std(centered_data, axis=0) with this you get close results, applying the std to the centered data does not change a lot\n",
    "    # ***************************************************\n",
    "    return std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the count of missing values in each columns\n",
    "def find_missing_values(data, headers=None):\n",
    "    num_rows, num_cols = data.shape\n",
    "    missing_count = np.zeros(num_cols, dtype=int)  \n",
    "    columns = np.linspace(0,num_cols, num_cols+1)\n",
    "    \n",
    "    for col in range(num_cols):\n",
    "        # Count the missing values\n",
    "        missing_count[col] = np.sum(np.isnan(data[:, col]))\n",
    "    if headers : \n",
    "        # Returning only the columns with missing values\n",
    "        missing_info = {headers[col]: missing_count[col] for col in range(num_cols) if missing_count[col] > 0}\n",
    "    else : \n",
    "        missing_info = {columns[col]: missing_count[col] for col in range(num_cols) if missing_count[col] > 0}\n",
    "    return missing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove columns with missing values\n",
    "def remove_high_missing_columns(data):\n",
    "    num_rows, num_cols = data.shape\n",
    "    threshold = 0  # For now, i put this value, I don't know what is a good treshold\n",
    "    missing_count = find_missing_values(data) \n",
    "\n",
    "    # Create a mask for columns to keep\n",
    "    columns_to_keep = [col for col in range(num_cols) if missing_count.get(col, 0) <= threshold]\n",
    "\n",
    "    # Return a new array with only the columns that meet the criteria\n",
    "    return data[:, columns_to_keep], columns_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_on_data(data, headers):\n",
    "# Créer un dictionnaire pour stocker les informations\n",
    "    column_info = {}\n",
    "    if headers :\n",
    "        columns = headers\n",
    "    else : \n",
    "        columns = np.linspace(0,num_cols, num_cols+1)\n",
    "    num_rows, num_cols = data.shape\n",
    "\n",
    "    for col in range(data.shape[1]):\n",
    "        # Récupérer la colonne\n",
    "        column_values = data[:, col]\n",
    "\n",
    "        # Déterminer le type de variable\n",
    "        unique_values = set(column_values)  # Récupérer les valeurs uniques\n",
    "        length = len(unique_values)\n",
    "        min_value = min(unique_values)\n",
    "        max_value = max(unique_values)\n",
    "        \n",
    "        # Ajouter des informations sur la colonne\n",
    "        column_info[columns[col]] = {\n",
    "            'colonne' : columns[col],\n",
    "            'length': length,\n",
    "            #'unique_values': unique_values\n",
    "            'min value' : min_value,\n",
    "            'max value' : max_value    \n",
    "        }\n",
    "\n",
    "    return column_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', '_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'DISPCODE', 'SEQNO', '_PSU', 'CTELENUM', 'PVTRESD1', 'COLGHOUS', 'STATERES', 'CELLFON3', 'LADULT', 'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'CTELNUM1', 'CELLFON2', 'CADULT', 'PVTRESD2', 'CCLGHOUS', 'CSTATE', 'LANDLINE', 'HHADULT', 'GENHLTH', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', 'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'CHECKUP1', 'BPHIGH4', 'BPMEDS', 'BLOODCHO', 'CHOLCHK', 'TOLDHI2', 'CVDSTRK3', 'ASTHMA3', 'ASTHNOW', 'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1', 'HAVARTH3', 'ADDEPEV2', 'CHCKIDNY', 'DIABETE3', 'DIABAGE2', 'SEX', 'MARITAL', 'EDUCA', 'RENTHOM1', 'NUMHHOL2', 'NUMPHON2', 'CPDEMO1', 'VETERAN3', 'EMPLOY1', 'CHILDREN', 'INCOME2', 'INTERNET', 'WEIGHT2', 'HEIGHT3', 'PREGNANT', 'QLACTLM2', 'USEEQUIP', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON', 'SMOKE100', 'SMOKDAY2', 'STOPSMK2', 'LASTSMK2', 'USENOW3', 'ALCDAY5', 'AVEDRNK2', 'DRNK3GE5', 'MAXDRNKS', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN', 'FVORANG', 'VEGETAB1', 'EXERANY2', 'EXRACT11', 'EXEROFT1', 'EXERHMM1', 'EXRACT21', 'EXEROFT2', 'EXERHMM2', 'STRENGTH', 'LMTJOIN3', 'ARTHDIS2', 'ARTHSOCL', 'JOINPAIN', 'SEATBELT', 'FLUSHOT6', 'FLSHTMY2', 'IMFVPLAC', 'PNEUVAC3', 'HIVTST6', 'HIVTSTD3', 'WHRTST10', 'PDIABTST', 'PREDIAB1', 'INSULIN', 'BLDSUGAR', 'FEETCHK2', 'DOCTDIAB', 'CHKHEMO3', 'FEETCHK', 'EYEEXAM', 'DIABEYE', 'DIABEDU', 'CAREGIV1', 'CRGVREL1', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPRB1', 'CRGVPERS', 'CRGVHOUS', 'CRGVMST2', 'CRGVEXPT', 'VIDFCLT2', 'VIREDIF3', 'VIPRFVS2', 'VINOCRE2', 'VIEYEXM2', 'VIINSUR2', 'VICTRCT4', 'VIGLUMA2', 'VIMACDG2', 'CIMEMLOS', 'CDHOUSE', 'CDASSIST', 'CDHELP', 'CDSOCIAL', 'CDDISCUS', 'WTCHSALT', 'LONGWTCH', 'DRADVISE', 'ASTHMAGE', 'ASATTACK', 'ASERVIST', 'ASDRVIST', 'ASRCHKUP', 'ASACTLIM', 'ASYMPTOM', 'ASNOSLEP', 'ASTHMED3', 'ASINHALR', 'HAREHAB1', 'STREHAB1', 'CVDASPRN', 'ASPUNSAF', 'RLIVPAIN', 'RDUCHART', 'RDUCSTRK', 'ARTTODAY', 'ARTHWGT', 'ARTHEXER', 'ARTHEDU', 'TETANUS', 'HPVADVC2', 'HPVADSHT', 'SHINGLE2', 'HADMAM', 'HOWLONG', 'HADPAP2', 'LASTPAP2', 'HPVTEST', 'HPLSTTST', 'HADHYST2', 'PROFEXAM', 'LENGEXAM', 'BLDSTOOL', 'LSTBLDS3', 'HADSIGM3', 'HADSGCO1', 'LASTSIG3', 'PCPSAAD2', 'PCPSADI1', 'PCPSARE1', 'PSATEST1', 'PSATIME', 'PCPSARS1', 'PCPSADE1', 'PCDMDECN', 'SCNTMNY1', 'SCNTMEL1', 'SCNTPAID', 'SCNTWRK1', 'SCNTLPAD', 'SCNTLWK1', 'SXORIENT', 'TRNSGNDR', 'RCSGENDR', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'EMTSUPRT', 'LSATISFY', 'ADPLEASR', 'ADDOWN', 'ADSLEEP', 'ADENERGY', 'ADEAT1', 'ADFAIL', 'ADTHINK', 'ADMOVE', 'MISTMNT', 'ADANXEV', 'QSTVER', 'QSTLANG', 'MSCODE', '_STSTR', '_STRWT', '_RAWRAKE', '_WT2RAKE', '_CHISPNC', '_CRACE1', '_CPRACE', '_CLLCPWT', '_DUALUSE', '_DUALCOR', '_LLCPWT', '_RFHLTH', '_HCVU651', '_RFHYPE5', '_CHOLCHK', '_RFCHOL', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_DRDXAR1', '_PRACE1', '_MRACE1', '_HISPANC', '_RACE', '_RACEG21', '_RACEGR3', '_RACE_G1', '_AGEG5YR', '_AGE65YR', '_AGE80', '_AGE_G', 'HTIN4', 'HTM4', 'WTKG3', '_BMI5', '_BMI5CAT', '_RFBMI5', '_CHLDCNT', '_EDUCAG', '_INCOMG', '_SMOKER3', '_RFSMOK3', 'DRNKANY5', 'DROCDY3_', '_RFBING5', '_DRNKWEK', '_RFDRHV5', 'FTJUDA1_', 'FRUTDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN', '_MISVEGN', '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_VEGESUM', '_FRTLT1', '_VEGLT1', '_FRT16', '_VEG23', '_FRUITEX', '_VEGETEX', '_TOTINDA', 'METVL11_', 'METVL21_', 'MAXVO2_', 'FC60_', 'ACTIN11_', 'ACTIN21_', 'PADUR1_', 'PADUR2_', 'PAFREQ1_', 'PAFREQ2_', '_MINAC11', '_MINAC21', 'STRFREQ_', 'PAMISS1_', 'PAMIN11_', 'PAMIN21_', 'PA1MIN_', 'PAVIG11_', 'PAVIG21_', 'PA1VIGM_', '_PACAT1', '_PAINDX1', '_PA150R2', '_PA300R2', '_PA30021', '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTACT1', '_LMTWRK1', '_LMTSCL1', '_RFSEAT2', '_RFSEAT3', '_FLSHOT6', '_PNEUMO2', '_AIDTST3']\n"
     ]
    }
   ],
   "source": [
    "column_info = get_info_on_data(x_train, headers_train)\n",
    "print(headers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colonne': '_STATE', 'length': 12, 'min value': np.float64(1.0), 'max value': np.float64(12.0)}\n"
     ]
    }
   ],
   "source": [
    "print(column_info[\"_STATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_nan = find_missing_values(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_x_train, columns_to_keep = remove_high_missing_columns(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328135, 82)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n",
      "239\n",
      "328103\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#print(column_with_nan)\n",
    "print(x_train.shape)\n",
    "print(len(column_with_nan))\n",
    "print(max(column_with_nan.values()))\n",
    "print(min(column_with_nan.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8\n",
    "    you will have 80% of your data set dedicated to training\n",
    "    and the rest dedicated to testing. If ratio times the number of samples is not round\n",
    "    you can use np.floor. Also check the documentation for np.random.permutation,\n",
    "    it could be useful.\n",
    "\n",
    "    Args:\n",
    "        x: numpy array of shape (N,), N is the number of samples.\n",
    "        y: numpy array of shape (N,).\n",
    "        ratio: scalar in [0,1]\n",
    "        seed: integer.\n",
    "\n",
    "    Returns:\n",
    "        x_tr: numpy array containing the train data.\n",
    "        x_te: numpy array containing the test data.\n",
    "        y_tr: numpy array containing the train labels.\n",
    "        y_te: numpy array containing the test labels.\n",
    "\n",
    "    >>> split_data(np.arange(13), np.arange(13), 0.8, 1)\n",
    "    (array([ 2,  3,  4, 10,  1,  6,  0,  7, 12,  9]), array([ 8, 11,  5]), array([ 2,  3,  4, 10,  1,  6,  0,  7, 12,  9]), array([ 8, 11,  5]))\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # ***************************************************\n",
    "    indices = np.random.permutation(len(x))\n",
    "    x_perm = x[indices]\n",
    "    y_perm = y[indices]\n",
    "    split = int(np.floor(ratio*len(x)))\n",
    "    x_tr = x_perm[0:split]\n",
    "    x_te = x_perm[split:len(x_perm)]\n",
    "    y_tr = y_perm[0:split]\n",
    "    y_te = y_perm[split:len(x_perm)]\n",
    "    # ***************************************************\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_data_train = standardize(sliced_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_val, y_tr, y_val = split_data(x = std_data_train, y = y_train, ratio = ratio, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262508, 82)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the split of 80.0 we have, for the training set a shape of (262508, 82) and for the validation set (65627, 82)\n"
     ]
    }
   ],
   "source": [
    "print(f\"After the split of {ratio*100} we have, for the training set a shape of {x_tr.shape} and for the validation set {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(y_true, y_pred_proba, threshold=0):\n",
    "    \"\"\"Calculate and print classification metrics given the true labels and predicted probabilities.\n",
    "    \n",
    "    Args:\n",
    "        y_val: numpy array of shape (N,), N is the number of samples. True labels.\n",
    "        y_pred_proba: numpy array of shape (N,), predicted probabilities for class 1.\n",
    "        threshold: scalar. The threshold to convert probabilities to binary predictions.\n",
    "    \n",
    "    Returns:\n",
    "        accuracy, precision, recall (TPR), FPR, F1-score\n",
    "    \"\"\"\n",
    "    # Step 1: Convert probabilities to binary predictions using the threshold\n",
    "    y_pred = np.where(y_pred_proba >= threshold, 1, -1)\n",
    "    \n",
    "    # Step 2: Calculate TP, FP, TN, FN\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FP = np.sum((y_true == 1) & (y_pred == -1))\n",
    "    TN = np.sum((y_true == -1) & (y_pred == -1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == -1))\n",
    "    \n",
    "    # Step 3: Calculate metrics\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # True Positive Rate\n",
    "    fpr = FP / (FP + TN) if (FP + TN) > 0 else 0  # False Positive Rate\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall (TPR): {recall}\")\n",
    "    print(f\"FPR: {fpr}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    \n",
    "    return accuracy, precision, recall, fpr, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tx, w):\n",
    "    \"\"\"Make predictions using the learned weights.\"\"\"\n",
    "    return tx @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 0.4803011171652391\n"
     ]
    }
   ],
   "source": [
    "w, train_mse = least_squares(y_tr, x_tr)\n",
    "#print(f\"Trained weights: {w}\")\n",
    "print(f\"Training MSE: {train_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.48191135689480163\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the trainig set\n",
    "y_pred = predict(x_val, w)\n",
    "\n",
    "# Compute MSE on the test set\n",
    "test_mse = compute_MSE(y_val, x_val, w)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17758127  0.06641111  0.27531845 -0.09796116 -0.21646513  0.10909002\n",
      " -0.17809572  0.06971775 -0.25512041 -0.11519682]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0\n",
      "Accuracy: 0.9677994742771311\n",
      "Precision: 0.8788627935723115\n",
      "Recall (TPR): 0.8788627935723115\n",
      "FPR: 0.018568141832453647\n",
      "F1-Score: 0.8788627935723115\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, fpr, f1 = classification_metrics(y_val, y_pred, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sliced = x_test[:, columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109379, 82)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_sliced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_subm = predict(x_test_sliced, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.08867459e+09 -6.24998961e+08 -2.74831505e+09 -1.07912041e+09\n",
      " -6.37052305e+09 -5.89932078e+09 -6.24076083e+08 -3.17680476e+09\n",
      " -4.19301824e+09 -1.12069487e+09 -3.21821134e+09 -5.26872186e+09\n",
      " -1.63224584e+09 -1.57994191e+09 -2.66575254e+09 -3.14583416e+09\n",
      " -1.57889649e+09 -1.60085937e+09 -1.17270502e+09 -2.64951253e+09]\n",
      "-3425780992.976299\n",
      "-6428292305.751772\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_subm[:20])\n",
    "print(np.mean(y_pred_subm))\n",
    "print(np.min(y_pred_subm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_submission = np.where(y_pred >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_submission[:20])\n",
    "print(np.mean(y_pred_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_csv_submission(test_ids, y_pred, \"submission_ls\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_MA1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
