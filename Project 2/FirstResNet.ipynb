{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to detect the presence of AAR cracks on the surface of concrete walls. These cracks are quite thin, web-shaped, and subtle to detect precisely.\n",
    "We have recently extracted a dataset of small image patches (128*128px), which is suitable for binary classification. Data is already split in train/val/test folds.\n",
    "Note that the patches were extracted from large wall images (which you can deduce from the filenames), and each train/val/test split contains patches from different walls to ensure proper evaluation. Also note that the dataset is unbalanced (about 13% of positive samples), this has to be taken into account for training and evaluation.\n",
    "I see following tasks:\n",
    "1. Train at least two different neural network classifiers, one being a CNN (e.g., ResNet, VGG, AlexNet...), and the other being a vision transformer (ViT).\n",
    "2. Optimize their performance by adjusting the model size, learning parameters, use of pretrained weights, data augmentations, sampling strategies to tackle the imbalance, etc.\n",
    "3. Visualize and analyze the predictions, in particular the mistakes of the model. For ViT, visualize the attention maps.\n",
    "As a deliverable, along with the 4 page report and a working code, also include 3 text files with the final predictions of each model over the three data splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\nathan\\\\Documents\\\\EPFL\\\\Cours_MA1\\\\ML\\\\ML_course\\\\projects\\\\aar_crack_wall_ds.rar\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m val_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnathan\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEPFL\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCours_MA1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mML\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mML_course\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprojects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124maar_crack_wall_ds.rar\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Directory containing validation images\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create a dataset for the training and validation data with the specified transformations\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(root\u001b[38;5;241m=\u001b[39mtrain_dir, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m     16\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mImageFolder(root\u001b[38;5;241m=\u001b[39mval_dir, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Load the datasets into DataLoader for batching\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\natha\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    321\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m ):\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    329\u001b[0m         root,\n\u001b[0;32m    330\u001b[0m         loader,\n\u001b[0;32m    331\u001b[0m         IMG_EXTENSIONS \u001b[38;5;28;01mif\u001b[39;00m is_valid_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    332\u001b[0m         transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[0;32m    333\u001b[0m         target_transform\u001b[38;5;241m=\u001b[39mtarget_transform,\n\u001b[0;32m    334\u001b[0m         is_valid_file\u001b[38;5;241m=\u001b[39mis_valid_file,\n\u001b[0;32m    335\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    336\u001b[0m     )\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\natha\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    140\u001b[0m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     allow_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 149\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_classes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[0;32m    150\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[0;32m    152\u001b[0m         class_to_idx\u001b[38;5;241m=\u001b[39mclass_to_idx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m         allow_empty\u001b[38;5;241m=\u001b[39mallow_empty,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\natha\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32mc:\\Users\\natha\\anaconda3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\nathan\\\\Documents\\\\EPFL\\\\Cours_MA1\\\\ML\\\\ML_course\\\\projects\\\\aar_crack_wall_ds.rar\\\\train'"
     ]
    }
   ],
   "source": [
    "# Image preprocessing transformations\n",
    "transform = transforms.Compose([\n",
    "    # Convert images to tensors (necessary for PyTorch models)\n",
    "    transforms.ToTensor(),  \n",
    "])\n",
    "\n",
    "# Loading datasets from specified directories\n",
    "train_dir = r'C:\\Users\\nathan\\Documents\\EPFL\\Cours_MA1\\ML\\ML_course\\projects\\aar_crack_wall_ds.rar\\train'  # Directory containing training images\n",
    "val_dir = r'C:\\Users\\nathan\\Documents\\EPFL\\Cours_MA1\\ML\\ML_course\\projects\\aar_crack_wall_ds.rar\\validation'  # Directory containing validation images\n",
    "\n",
    "# Create a dataset for the training and validation data with the specified transformations\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "# Load the datasets into DataLoader for batching\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Extract one image from class 0 and one from class 1\n",
    "def get_image_by_label(dataset, label):\n",
    "    for img, lbl in dataset:\n",
    "        if lbl == label:\n",
    "            return img, lbl\n",
    "    return None, None  # In case no image is found\n",
    "\n",
    "# Get an image with label 0 and label 1 from the train dataset\n",
    "image_0, label_0 = get_image_by_label(train_dataset, 0)\n",
    "image_1, label_1 = get_image_by_label(train_dataset, 1)\n",
    "\n",
    "# Display the images with their labels\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(image_0.permute(1, 2, 0))  # Convert tensor shape for display (C, H, W) to (H, W, C)\n",
    "axes[0].set_title(f\"Label: {label_0}\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Display image with label 1\n",
    "axes[1].imshow(image_1.permute(1, 2, 0))  # Convert tensor shape for display\n",
    "axes[1].set_title(f\"Label: {label_1}\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device for training (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load a pre-trained ResNet model and modify the final layer for binary classification (2 classes)\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the last fully connected layer for 2 classes (binary classification)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function (CrossEntropyLoss) and optimizer (Adam)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Function to train the model for 2 epochs\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=2):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print the average loss for the epoch\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        evaluate_model(model, val_loader)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Train the model for 2 epochs\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Turn off gradients for evaluation\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "            \n",
    "            total += labels.size(0)  # Update total number of samples\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "    accuracy = 100 * correct / total  # Calculate accuracy as a percentage\n",
    "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# After training, evaluate the model on the validation set\n",
    "evaluate_model(model, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
